{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlkO-MhBY2BE"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AdmiralHonda/ml_intro/blob/main/appendix/logic.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nl_E6T8bl4vC"
      },
      "outputs": [],
      "source": [
        "#@title おまじない（単語分割ツールのインストール）\n",
        "# 下準備です。すみませんが、おまじないだと思ってください\n",
        "# 日本語や韓国語などのアジア圏の言語における文章を単語に分割するツールのインストールを行っています。\n",
        "\n",
        "# 形態素分析ライブラリーMeCab と 辞書(mecab-ipadic-NEologd)のインストール \n",
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab > /dev/null # mecabの利用に必要なライブラリのインストール\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null                    # gitから辞書ファイルのクローン\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n > /dev/null 2>&1                   # クローンした辞書のインストール\n",
        "!pip install mecab-python3==0.7 > /dev/null                                                             # 0.7意外だと謎のエラーが発生して安定しないことがある\n",
        "\n",
        "# シンボリックリンクによるエラー回避\n",
        "!ln -s /etc/mecabrc /usr/local/etc/mecabrc                                                              # 辞書の参照先にインストール先のディレクトリを追加\n",
        "!echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"                                                    # mecabの設定ファイルに新しく辞書を追加したことを追記"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSxucG1omf6r"
      },
      "source": [
        "# **学習と推論**\n",
        "\n",
        "この章では今までの学習を生かしてアプリの根幹となる部分を構築します。  \n",
        "具体的には以下の処理を行います。  \n",
        "\n",
        "- 必要なデータの配置\n",
        "- 分散表現（単語をベクトル化したもの）の学習\n",
        "- 分散表現を生かした文章ベクトルの生成\n",
        "- ユーザーの入力の文章ベクトルへの変換\n",
        "- 簡単に試してみよう\n",
        "\n",
        "## **演習環境**\n",
        "\n",
        "![講習会＿演習環境.png](https://pub-dd9160b14dab4fd08df96674dc1b9692.r2.dev/講習会＿演習環境.png)\n",
        "\n",
        "簡単単に今見ている演習環境について説明します。  \n",
        "ここでは上の図のように皆さんのマシンではなく、googleが用意した仮想マシン上で実行し手皆さんはその結果をブラウザで確認するような実行環境になっています。  \n",
        "そのためデータなどに関してはgoogle driveを用いてやり取りを行う様になります。\n",
        "ちなみにこのファイルも保存をすると自動的に皆さんのdrive上に保存されます。  \n",
        "\n",
        "### jupter notebook\n",
        "jupter notebookというコマンドラインで実行するのではなくてコードと実行環境とワードがすべて同じファイルに詰まったものを使うといったイメージのツールを用います。  \n",
        "基本的にセルと呼ばれる四角い枠の中にコードや説明書き（マークダウン）を記述します。  \n",
        "私が今見ているセルにはマークダウンで説明書きをしているセルになります。  \n",
        "その他にもコードを記述したセルがあります。下で沢山記述しています。実行する際にはセルの左上にある再生ボタンをクリックしてもらえれば実行できます。  \n",
        "\n",
        "## **使用するデータ**\n",
        "\n",
        "### **大容量データを扱う工夫**\n",
        "今回単語の意味を学習するのに使用するデータはwikipediaの本文すべてです。  \n",
        "そのデータはテキストファイルではありますが、3.5Gもあります。  \n",
        "これだけ大きくなるとGoogleDriveでダウンロードする際にウイルスチェックができないので確認画面が表示されます。  \n",
        "そうするとプログラムから呼び出した際には、確認画面のhtmlが入力され、データ本体は読み込めなくなります。  \n",
        "#### **Colabのアップロードの遅さ**\n",
        "またこのColab環境では無料で使える代わりに、データのアップロードがとても遅く、これほどの規模のデータとなると、いったんローカルにダウンロードしてからアップロードすると何時間もかかってしまいます。  \n",
        "そのため、今起動しているcolabの仮想マシンに皆さんのGoogleDriveをマウント（別のマシンのディレクトリを今のマシンでも扱えるようにする）することで大容量のデータのやり取りを行います。  \n",
        "正直それでも遅いですが、まだ現実的な時間で実行することができます。  \n",
        "#### **Driveへデータを配置する**\n",
        "まずは皆さんのGoogleDriveに下記のデータを配置してください。  \n",
        "注意として、今のアカウントの保存容量を確認してください。  \n",
        "今回の演習では約5Gのデータをダウンロードするので、空き容量がない場合は**購入**か**データの削除**が必要です。  \n",
        "ただ、対面でのword2vecの学習は数時間かかるので行いません。なので今回は学習済みデータを配るので、最低1.5Gくらいの空きがあれば対応できます。  \n",
        "また、日大のアカウントでは容量無限大なので日大の在校生の場合は学校のアカウントで行うといいでしょう。  \n",
        "ほかのデータと区別できるように皆さんのdriveの一番上の階層に`/python_ml_intro`というディレクトリを作成し、その中に下記のデータを配置してください。  \n",
        "\n",
        ">[wikiの学習データ](https://admiralhonda-share-tech.on.drv.tw/python_ml_intro/data/class_select_app/wiki_wakati.txt)  \n",
        "対面の講義ではおそらく使用しませんが、宿題や確認で学習する際に使用してください。  \n",
        "\n",
        ">[wikiから学習した学習済みデータ](https://admiralhonda-share-tech.on.drv.tw/python_ml_intro/data/class_select_app/wiki_test_vec.pt)  \n",
        "対面でプレゼンをする際は学習する時間がもったいないので既に学習済みのものを使用します。  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOEQJTCWCXv1"
      },
      "source": [
        "## ドライブのマウント解説\n",
        "`drive.mount(\"/content/drive\")`についてですが、あなたのGoogleDriveのルートディレクトリを`/content/drive`として今の実行環境では扱うようにしています。  \n",
        "現在Colabで実行しているディレクトリは`/content`直下になるのでその下に`drive`というディレクトリを作成していることになります。  \n",
        "パソコンで見ている場合は左側にあるファルダマークをクリックしてみるとよいでしょう。  \n",
        "今の作業ディレクトリの下にあるツリーが見れます。  \n",
        "また`/content/drive`の下に`/My Drive`というディレクトリがありますが、その下にあなたのGoogleDriveのマイドライブの中身が入っているはずです。  \n",
        "共有フォルダは認識されなかったと思います。  \n",
        "この先、先ほど紹介した通りにファイルを配置した際には`/content/drive/My Drive/python_ml_intro`の後にファイル名を記述すれば参照できます。  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bf7zHbKwGab",
        "outputId": "e4f3b53a-7729-433b-89ac-e8729f6d1dcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ドライブのマウント\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1dfw1lJiV8P"
      },
      "source": [
        "## **word2vecの学習**  \n",
        "\n",
        "下記のコードの解説をします。\n",
        "\n",
        "### **学習するためのデータ型に**  \n",
        "\n",
        "学習するために単語が事前にスペースで区切られたテキストファイルを用意しましたが、さらに改行`\\n`ごとに分割して適切な学習単位にする必要があります。  \n",
        "前処理にて１記事毎や１コンテンツ毎に改行を入れていたのはこのためです。  \n",
        "`word2vec`のメソッドである`LineSentence`でその処理を行います。  \n",
        "引数に分割するテキストファイルのパスを渡します。  \n",
        "\n",
        "### **学習**  \n",
        "\n",
        "学習する際にテキストデータを改行で区切った`sentences`を引数にとるのはもちろんのこと、その他にもいくつか指定しています。それらについて触れます。  \n",
        "- iter  \n",
        "試行回数。何回学習データで学習するかの回数です。何回問題集を解くのかだと思えばええです。\n",
        "- size  \n",
        "入力層の列数。\n",
        "- sg  \n",
        "cbowかskip-gramかの選択。1か0で指定する。\n",
        "- min_count  \n",
        "学習データ中にあまり頻出しない単語を排除するために、出現回数が`min_count`以内であったら学習対象から除外するという設定。不必要な学習単語数の増加は重み（行列）の行数が増えるので計算時間が増えます。また、最終的にデータの量が多くなりアプリで使用する際に読み込み時間が増加する懸念があります。  私の実装ではコンテナを使用することが前提なので数秒の差は大きく見ています。\n",
        "- window  \n",
        "周辺の単語をどれだけ考慮するかの数。windowサイズです。\n",
        "- workers  \n",
        "実行するプロセスの数です。環境の論理cpu数を指定するとよいでしょう\n",
        "- hs  \n",
        "損失計算の際に階層的ソフトマックスかネガティブサンプリングを選ぶかの指定。1か0で指定。\n",
        "\n",
        "### **保存**\n",
        "\n",
        "最後の一文では入力層の部分のみを取り出して保存しています。  \n",
        "`Word2Vec`クラスのパラメータである`wv`が入力層に当たります。  \n",
        "保存するメソッドの`binary=True`はテキストでなくバイナリで保存するように指定しています。  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86eEqXxKY2BI"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "とりあえず学習してみる\n",
        "この設定だと、２時間近くかかります。\n",
        "\"\"\"\n",
        "from gensim.models import word2vec\n",
        "\n",
        "sentences = word2vec.LineSentence(\"/content/drive/MyDrive/python_ml_intro/wiki_wakati.txt\")\n",
        "model = word2vec.Word2Vec(sentences, iter=5,size=300,sg=1,min_count=5, window=3, workers=4,hs=0)\n",
        "model.wv.save_word2vec_format(\"/content/drive/MyDrive/python_ml_intro/wiki_test_vec.pt\",binary=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QL5xc0A1pdy"
      },
      "source": [
        "## 学習データの読み込み\n",
        "\n",
        "前述したコードで.pt(区別のために適当につけた拡張子)とついたファイルを単語の分散表現として保存しました。  \n",
        "今度はそれを`KeyVectors`として読み込みます。学習はできませんが、単語間の**意味**的な類似度や特定の単語のベクトルを抜き出すことができます。  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4H7ajdVY2BI"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "wiki_model = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/python_ml_intro/wiki_test_vec.pt\",binary=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExF7Mblg4XgJ"
      },
      "source": [
        "## コンテンツの読み込み\n",
        "\n",
        "これ以降の処理ではwikipediaから学んだ単語の意味を用いてコンテンツの意味を含んだベクトルを生成します。  \n",
        "\n",
        "今回はサンプルとして授業の検索アプリを作成します。  \n",
        "少ないですが、20件の講義データをcsv形式のファイルといて用意しています。  \n",
        "これを読み込み、各講義データごとに所属する単語ベクトルの平均をとり、文章ベクトルを生成します。  \n",
        "\n",
        "### pandas\n",
        "\n",
        "pythonのライブラリで表形式のデータを処理するのに非常に便利です。  \n",
        "この３年生向けのイントロでは触れませんが、データからより学習するために不必要な記号を削除したり改行文字を取り払うなどの前処理をするときなどにも役に立ちます。  \n",
        "表のデータを列ごとに分析したり、データベースのように検索することもできます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fff_zTQ5l2o8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "classroom_info = pd.read_csv(\"https://admiralhonda-share-tech.on.drv.tw/python_ml_intro/data/class_select_app/class_info.csv\")  # データの読み込み\n",
        "classroom_info.head(10)                                                                                                         # 先頭４個分のデータを確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmfhbmMMl2o8",
        "outputId": "588b66da-6b21-4f51-bc13-90d973cc07d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'教科名': 'プログラミングの基礎及び演習', '担当者': '和泉 勇治', '授業目的': 'プログラミングの基礎及び演習は，ソフトウェアにより実現する機能を分析し，処理手順を記述し，プログラミング言語の基本文法を用い，構造化されたプログラムの作成の理解にある。', '教育目標': '(1) C言語の基本文法を理解し，分岐や繰返しからなる基本的な命令をC言語で記述する方法を理解する。更に，配列や構造体および機能的な処理をまとめる関数作成の考えを理解し，配列や構造体を扱う関数を用いたより実用的な形式のプログラムをC言語で記述する方法を理解する。(2) 与えられた課題を分析し，3つの基本制御構造（順次，分岐，繰り返し）を適切に組み合わせ，フローチャートなどにより処理手順を図式化して記述できる。加えて，既述した処理手順をC言語の命令に対応させ，プログラムを作成できる。(3) 自主的学修の成果となる課題レポートを毎回提出することにより，自主的な学修を継続することができる。', '概要': '講義において，分岐，繰返し，関数，配列，構造体といったＣ言語によるプログラミングについてソースコード例を示しながら解説する。講義に続き行われる演習においては，第1回から第5回，第7回から第11回，第13回と第14回に出題する課題について，問題分析から処理手順の図式化およびプログラムの実装・確認までを実施する。演習において，教員とTAが適宜指導を行うことにより，演習内容における理解の向上を図る。演習で作成したソースコードは課題提出システムにより正しく実行できるかを各人で確認できる。なお，日々の自主学修の目標となるように，中間試験を２回実施し，試験終了後に解説を行い理解の定着を図る。', '成績評価': '評価は絶対評価とし，授業内試験を50%，中間試験を30%，演習課題およびレポートを20%，これらを統合して100点満点とし，60点以上を合格とする。全てのレポートを提出しない場合には，授業内試験の受験資格を失う。期末試験において理解度が不十分であると考えられる場合は，再試験を行うことがある。', '課題': '演習において，教員およびTAにより，正しい設計方法を指導し，作成したソースプログラムは正しい設計方法，コーディング方法，エラーの分析方法を指導し，誤りを指摘し修正方法を指導する。演習課題に対して，作成したソースコードは”課題提出システム”を用いて各人が提出するとともに，ソースコードの正しさを%表示で各人へ示し自律的な学修を促す。2回の中間試験については，その正解および解き方を授業内で解説するとともに，各人の点数を個別に設問毎の内訳をともに提示し各人の弱点と強化ポイントを把握させる。'}, {'教科名': 'データ構造入門及び演習', '担当者': '溝口\\u3000知広', '授業目的': 'C言語プログラムに関する基本的な知識を身につけるとともにデータ構造とアルゴリズムを用いた基本的なＣ言語プログラミングのコーディング・デバッギングを理解する。', '教育目標': '具体的な達成目標：(1)デバッグの仕方と再帰呼出しを用いた繰り返し処理が理解できる。(2)アドレスを用いた処理方法およびポインタが理解できる。(3)ポインタによる配列および文字列処理が理解できる。(4)構造体を使用した多数のデータをまとめて処理する方法およびポインタによる構造体の処理方法が理解できる。(5)ファイルに対するデータの読み書き処理方法が理解できる。(6)バブルソートおよび挿入方を用いた整列処理が理解できる。(7)クイックソートを用いた整列処理が理解できる。(8)線形探索と二分探索を用いた探索処理が理解できる。(9)リスト構造を用いたデータ格納処理が理解できる。(10)スタックおよびキュー構造を用いたデータ格納処理が理解できる。', '概要': '講義において，教科書と配布されるプリントを用いて文法，アルゴリズム，データ構造の特徴や考え方，C言語を用いた記述について例を示しながら解説する．演習では演習問題で指示されるプログラムを作成し，プログラムの実行特性を分析する．その結果は，各授業後にレポートにまとめて提出する．レポートとして提出された課題は添削した後に返却し，自主学習の機会が多くなるようにしている．また，日々の自主学習の目標となるように中間試験を２回実施し，試験終了後に解説を行い理解の向上を図る．', '成績評価': '評価は絶対評価とし，レポートを１０点，中間試験を各２０点，授業内試験５０点とし，６０点以上を合格とする．原則として４回以上欠席した場合，授業内試験の受験資格を失う．レポートを全て提出しない場合には，授業内試験の受験資格を失う．', '課題': 'レポートは採点を行い点数のみ返却する．点数によっては再提出を求める．中間試験の各問ごとの得点を開示し，各自の達成度を認識させる．'}, {'教科名': '確率統計及び演習', '担当者': '見越\\u3000大樹、岩井\\u3000俊哉', '授業目的': '確率的なデータの性質を理解し，データを正当に扱うことができるようになるため，その基本となる確率とその性質，統計処理の基礎および正規分布と統計的推定・検定を理解することを目的とする．', '教育目標': '（１）順列と組合わせの考え方を理解し、これらを用いて確率計算ができる，（２）条件付確率の考え方，ベイズの定理を理解し、確率計算の事例に適用できる、（３）確率分布、統計データにおける度数分布と標本化、および、各種代表値、標準偏差／分散、期待値などの意味を理解し、事例に適用できる（４）正規分布の意味を理解し、正規分布表を用いて確率計算の事例に適用できる，（５）平均値の区間推定を理解し，事例に適用できる（６）平均値の検定を理解し，事例に適用できる', '概要': '情報工学で種々のデータを統計的に処理することや，情報処理を行うにあたり誤差や不確定性を考慮するために確率的考え方が必要になることがある．講義では，まず確率の意味，順列や組み合わせなど場合の数をもとにした確率計算の考え方と方法を学ぶ．次に，条件つき確率の考え方とベイズの定理について学ぶ．つづいて、データから有効な情報を抽出するための基礎的な統計量とその計算方法について学ぶ．最後に，正規分布の意味を理解して，統計的な推論・検定の初歩的な方法について学ぶ．各授業に対して演習で具体的問題に応用できる能力を養う', '成績評価': '成績評価は絶対評価とし、講義と演習を５０：５０として評価し、６０点以上を合格とする。・講義では、(1)単元テスト：中間試験：期末試験＝３０：３０：４０％(2)中間試験：期末試験＝４０：６０％で評価し、高い方をその成績とする。・演習では、全１３回の演習の「基本問題」と「応用問題」の合計点を50点満点として成績評価とする。・単元テストはポータルサイト小テスト機能を用いて，授業中に締め切りを設けて実施する．・演習は，ポータルサイトの小テストを用いて，締め切り日時を設定して実施すする．・期末試験について，理解度が十分でないと考えられる場合は再試験を行うことがある。', '課題': '全13回の演習課題の解答解説を授業で行うか解説動画をClassroomにアップする．小テストの解答はポータルサイトから閲覧できるようにする．'}, {'教科名': '情報理論', '担当者': '源田 浩一', '授業目的': '情報の伝達において，情報を効率良く伝達する，情報を信頼性高く伝達する，情報を安全に伝達する，ことが求められる。「情報理論」は，符号化という手段で，情報を効率良く伝達するための基本的考え方を理解することにある。', '教育目標': '(1) 情報源のモデル化と，マルコフ情報源等の代表的な統計的性質を理解できる。(2) 情報源符号化の条件と，ハフマン符号等の代表的な符号化の実現法を理解できる。(3) 情報源符号化の限界と，情報源符号化定理を理解できる。(4) 情報量とエントロピーとの関係を理解できる。', '概要': '効率よく情報を伝達するために必要となる符号化について講義を行う。まず代表的な情報源のモデルと統計的性質の表現について解説する。次に情報伝達の効率化を可能とする代表的な符号化の実現法について解説をおこない，符号化の限界をあらわす情報源符号化定理を解説する。そして情報量の考え方とエントロピーとの関係について学ぶ。', '成績評価': '成績評価は絶対評価とし，中間レポート40%および授業内試験40%，授業出席や課題提出状況20%を総合して，60点以上を合格とする。', '課題': '授業での課題や中間レポートは授業で解説する。また点数等を提示し各自の達成度を認識させる。'}, {'教科名': '論理回路及び演習', '担当者': '見越 大樹、松村 哲哉', '授業目的': '回路素子を組合わせて構成する論理回路の動作を理解し、簡単な回路設計と作成を行うことができることを目的とする。', '教育目標': '（１）ビット表現と電圧の関係など、デジタルデータと電気信号の基本を理解する。（２）AND、OR、NOTなどの基本論理（命題論理）の意味を理解できる。（３）論理関数の基本的演算ができる、（４）論理関数や、ベン図を拡張したカルノー図を使うなどして、基本的な組み合わせ論理回路の設計ができる。（５）順序回路の基本論理を理解し応用できる。', '概要': 'まず電気回路の基本的事項を説明した後、AND,ORなどの論理回路素子入出力を電圧の１，０で表現することを説明する。論理の計算を行うための論理関数、論理的条件を表現する真理値表、視覚的な論理関数演算手段としてのカルノー図などにつづいて、組合わせ論理回路設計の考え方と方法を説明する。また、記憶機能を持つフリップフロップの動作、ならびにこれを応用したシフトレジスタやカウンタなどについても説明する。各種の組合わせ論理回路、順序回路を作製し動作させることで、その意味を理解する。', '成績評価': '評価は絶対評価とし、講義を50点満点、演習を50点満点とする。講義については①定期試験(100%)、②定期試験（70%）と小テスト（30%）の合計、いずれかが高い方を50点満点で評価する。演習については演習当日の進捗状況と口頭報告により、達成度を50点満点で評価する。講義と演習の合計点が60点以上を合格とする。', '課題': '小テストはポータルにて採点結果と解説を開示する。'}, {'教科名': 'コンピュータアーキテクチャＩ', '担当者': '松村 哲哉', '授業目的': '本科目は，コンピュータアーキテクチャの基礎知識を理解し，ノイマン型コンピュータの基本構成と要素技術を理解することにある．', '教育目標': '（１）コンピュータにおける数表現（整数，実数）を理解できる．（２）コンピュータにおける論理回路（組合せ論理回路，順序回路，応用回路）を理解できる．（３）ノイマン型コンピュータの基本構成と基本命令セットアーキテクチャを理解できる．（４）制御アーキテクチャを理解できる．（５）演算アーキテクチャを理解できる．（６）メモリアーキテクチャを理解できる．（７）入出力アーキテクチャを理解できる．', '概要': 'コンピュータ技術におけるアーキテクチャの位置づけとコンピュータ技術の歴史の概要を説明する．その後，現代のコンピュータの構成原理となっているノイマン型コンピュータの基本構成と要素技術について，具体的な事例を交えながら説明する．また，講義においては，例題を解くための時間を設け，この例題の解説を行うことにより，各自の理解度の向上を図る．', '成績評価': '評価は絶対評価とし、小テストで20%，授業内試験（１）で40%，授業内試験（２）で40%とする．小テストと２回の授業内試験で総合的に達成度を評価し、100点満点で60点以上を合格とする．なお，原則として，4回以上欠席した場合には，期末試験を受験することができない．', '課題': '小テストについては、採点結果の点数を開示する．'}, {'教科名': 'コンピュータアーキテクチャＩＩ', '担当者': '松村\\u3000哲哉', '授業目的': '本科目は，コンピュータアーキテクチャの基礎知識を理解し，ノイマン型コンピュータにおける高性能化のための基本技術について理解し，具体的な事例の動作を説明を目標とする．', '教育目標': '本科目の達成目標:（１）演算アーキテクチャ（乗算，除算）を理解できる．（２）メモリアーキテクチャ（キャッシュ，仮想メモリ）を理解できる．（３）制御アーキテクチャ（パイプライン）を理解できる．（４）命令レベル並列処理を理解できる．（５）マルチプロセッサを理解できる．（６）ベクトルコンピュータを理解できる．', '概要': '現代のコンピュータにおける演算アーキテクチャ（乗算，除算），メモリアーキテクチャ（キャッシュ，仮想メモリ），制御アーキテクチャ（パイプライン）について，具体的な事例を交えながら説明する．その後，現代のコンピュータの高速化のためのアーキテクチャである命令レベル並列処理，マルチプロセッサについて，具体的な事例を交えながら説明する．また，講義においては，例題を解くための時間を設け，この例題の解説を行うことにより，各自の理解度の向上を図る．', '成績評価': '評価は絶対評価とし、小テストで20%，授業内試験（１）で40%，授業内試験（２）で40%とする．小テストと２回の授業内試験で総合的に達成度を評価し、100点満点で60点以上を合格とする．なお，原則として，4回以上欠席した場合には，期末試験を受験することができない．', '課題': '小テストについては、採点結果の点数を開示する．'}, {'教科名': 'データベース工学', '担当者': '中村\\u3000和樹', '授業目的': 'データベース工学は，データベースシステムにおける基礎的な設計と操作の理解にある。', '教育目標': '(1) スキーマおよびデータモデリングを理解できる。（2） 正規化を理解できる。（3） 不整合および従属性を理解できる。（4） リレーショナル代数を理解できる。（5） SQLによるデータベースの操作を理解できる。(6) トランザクション処理を理解できる。（7） バックアップを理解できる。（8） アクセス制御を理解できる。（9） コミットメント制御を理解できる。', '概要': '現在のIT社会においてデータベースシステムはありとあらゆる場所，とりわけウェブと連携してインターネットの世界のインフラとして機能している。将来IT技術者としてこれらの世界へと入っていくためには，データベースシステムの基本概念，リレーショナルデータベースの設計およびその操作言語SQLを学び，論理的思考能力と実務処理能力を養うことが必要である。したがって，本授業ではデータベースシステムの基本概念，リレーショナルデータベースの設計およびその操作言語であるSQLを扱う。', '成績評価': '小テスト，課題，演習結果の提出から総合的に評価する。評価の内訳は，小テスト（25%），課題（20%），演習（15%），期末試験（40%）である。また，評価は絶対評価とする。原則として，授業を4回以上欠席した場合には単位を認定しない。提出物を期限までに提出していない場合は，欠席として取り扱う。なお，提出物を提出していない場合には減点法を取ることにより不合格とする場合がある。', '課題': '第2回〜第5回には課題に取り組むことにより自立的な学習を促す。なお，その解答例は授業内で解説する。第9回〜第11回のSQLの実践では，巡回を通して各人の操作および理解を助ける。期末試験については，正解の導き方を授業内で解説する。'}, {'教科名': 'WWWとJavaプログラミング及び演習', '担当者': '杉山 安洋、大山 勝徳', '授業目的': 'Java言語を用いたオブジェクト指向ソフトウェアの開発手法を理解することにある。', '教育目標': '(1) オブジェクト指向のソフトウエア開発手法を理解し、Java言語を用いて簡単なオブジェクト指向ソフトウエアが開発できる。(2) Webアプリケーションの動作原理を理解し、Java言語を用いて簡単なWebアプリケーションが開発できる。', '概要': '本科目の前半では、オブジェクト指向プログラミングの基本概念について学ぶ。後半は、JavaのサーブレットやJSPなどのサーバサイドのJavaプログラムの作成方法について学ぶ。演習は、講義と強く関連しており、講義で学んだ概念や知識を用いて演習で実際にプログラムを作成することにより、その概念をより深く理解する。', '成績評価': '(1) 評価は絶対評価で行う。中間試験（25%）、期末試験（25%）、演習レポート（50%）の合計点で評価し、60点以上を合格とする。(2) 演習のレポートはすべて提出する必要がある。(3) 全授業に出席することが原則である。やむを得ない事由がある場合には欠席を認めるが、講義または演習のいずれかを4回以上欠席した場合は成績評価の対象としない。', '課題': '提出されたプログラムは動作確認の上、状況を各自へ通知する。'}, {'教科名': '基礎オペレーティングシステム', '担当者': '菊間\\u3000一宏', '授業目的': 'オペレーティングシステムの構造，基本的な動作及びプロセス管理とメモリ管理の実現方法を理解し，システム設計などに応用できるようになることを目的とする。', '教育目標': '具体的な達成目標：(1) オペレーティング システムのインタフェースと構造，プログラムの実行と割り込み処理に伴う動作を理解し，適切な専門用語を用いて説明できる。(2) 入出力に伴うシステムの動作を理解し，磁気ディスクの管理，ファイル管理の具体例について説明できる。(3) プロセスの状態遷移 とその動作を理解し，状態の変化やCPUスケジューリング動作を示せる。(4)動的再配置の必要性と仕組みを理解し，ページングによる主記憶管理と仮想記憶によるシステムの動作について説明できる。(5) 上記に基づき，必要なメモリ量，空き領域，待ち時間，使用率等のシステム設計の基礎的な数値が算出できる。', '概要': 'オペレーティングシステムは，計算機資源の使用効率向上，ユーザに使い易い計算機インタフェースの提供，高度な分散型コミュニケーション環境などを提供している。システムの体系を理解し，アプリケーションを含めた設計への応用のために，具体的な条件が例示されながら講義が進められる。また，前回の授業で重要なものの理解度が確認できるように，日本大学工学部ポータルサイトの授業支援システムによる小テスト（10問程度）を第2回から第14回まで毎回受験する。理解の向上のため，小テスト終了後に各問の正解や解き方の解説がなされる。第13回までの授業スライドは，授業開始までに，ポータルサイトの授業資料にアップされる。第14回授業スライドは，期末試験問題の確定後にアップされる。小テストの解説スライド及び問題文のみのプリントは授業終了後にアップされる。', '成績評価': '成績は絶対評価とし，①定期試験（100%），②定期試験（60%）と小テスト（40%）の合計，何れかが60点以上が合格となる。定期試験において理解度が不十分であると考えられる場合は，再試験を受験することがある。', '課題': '小テスト終了後に解説がなされる。小テストの問題及び解説スライドはポータルの授業資料にアップされる。'}, {'教科名': '符号とセキュリティ', '担当者': '源田\\u3000浩一', '授業目的': '情報の伝達において，情報を効率良く伝達する，情報を信頼性高く伝達する，情報を安全に伝達することが求められる。「符号とセキュリティ」は，符号化という手段で，情報を信頼性高く伝達すること，情報を安全に伝達することの基本的考え方を理解することにある。', '教育目標': '(1) ハミング符号等の代表的な通信路符号化の実現法を理解できる。(2) 通信路のモデル化と統計的性質を理解できる。(3) 通信路符号化の限界と通信路符号化定理を理解できる。(4) セキュリティのための暗号化技術と認証技術の基本を理解できる。', '概要': '信頼性が高く安全な情報伝達を行うための符号化およびセキュリティについて講義を行う。符号化については，通信路の符号化について代表的な方法を解説するとともに，符号化の限界をあらわす通信路符号化定理を解説する。セキュリティについては，暗号化技術及び認証技術について解説する。', '成績評価': '成績評価は絶対評価とし，中間レポート40%および授業内試験40%，授業出席や課題提出状況20%を総合して，60点以上を合格とする。', '課題': '授業での課題や中間レポートは授業で解説する。また点数等を提示し各自の達成度を認識させる。'}, {'教科名': '画像情報処理及び演習', '担当者': '加瀬澤\\u3000正', '授業目的': '画像情報処理の基礎知識を理解し，そのプログラムを作成するための技術を修得することを目的とする。', '教育目標': '（１）光と色の基本的な性質を理解できる。（２）画像信号における標本化と量子化について理解できる。（３）濃淡情報の変換方法を理解できる。（４）幾何学的情報の変換方法を理解できる。（５）再標本化と補間処理方法について理解できる。（６）空間的情報の変換方法を理解できる。（７）２値画像処理方法を理解できる。（８）動画像処理方法を理解できる。（９）画像符号化方法を理解できる。（１０）画像情報処理を行うための基本的なプログラムが作成できる．', '概要': '講義では，画像情報処理に関する基礎知識について，具体的な事例を交えながら説明する。また，例題を解くための時間を設けるとともに，それらの例題の解説を行うことにより，理解度の向上を図る。演習では，画像情報処理を行うためのプログラミング課題を出題することにより，画像情報処理に関する理解度向上を図る。なお，講義及び演習における資料は，専用サイトからダウンロードできるようにするので，事前学修および事後学修で活用すること。（上記サイトのアクセス方法については，第1回目の講義もしくは演習において説明する。）', '成績評価': '授業は絶対評価とし，100点満点で，60点以上で合格とする。なお，原則として，講義，演習とも4回以上欠席した場合には，単位を修得することができない。また，理解度が十分でないと考えられる場合には，補講，補習課題，再試験を行うことがある。', '課題': '【講義】授業内試験については，試験終了後に解説を行う。また，小テストについては，ポータルサイトに，採点結果と正答を掲載する。【演習】授業内試験については，試験終了後に解説を行う。また，解説の後，それまでの演習内容に関する個別の質問に対して回答する。'}, {'教科名': '情報と職業', '担当者': '松村\\u3000哲哉', '授業目的': '「社会人として仕事をする」ということの目的、意義を理解し、キャリアプランを立案する方法を習得する。また、情報系企業の業種分野ごとに、企業の取り組みと技術者に求められる技術力と社会人基礎力について理解し、今後の学生生活の中で身につけておくべき技術力と社会人基礎力を向上させる対策を立案する,', '教育目標': '（１）「社会人として仕事をする」ということの目的、意義を理解し、キャリアプランを立案する方法を習得できる。。（２）将来、自分にとって本当に望ましい企業に就職するための準備として、情報系企業の業種分野ごとに、将来の動向、解決すべき課題、課題解決に向けての取り組みと技術者に求められる技術力と社会人基礎力について理解できる．（３）自分の就職する企業を想定して、志望理由と自分が所有すべき技術力と社会人基礎力を検討し、今後の学生生活の中で身につけておくべき技術力と社会人基礎力を向上させる対策を立案できる．', '概要': '授業は、キャリアデザインの講義を行い、自己分析等を通じて自分の将来設計についての手法を学ぶ。また、６名の社会人講師（情報関連企業に勤務）から、企業の業種分野ごとに将来の動向、解決すべき課題、課題解決に向けての取り組みと技術者に求められる技術力と社会人基礎力のお話を伺い、その後、就職する企業を想定して、志望理由と自分が所有すべき技術力と社会人基礎力を学ぶ。', '成績評価': '評価は絶対評価とし、授業内試験（１）で50％、講義毎のレポートで50％の成績評価を行い、総合して100点満点で採点する．合計60点以上を合格とする．', '課題': 'レポートの採点結果の点数については随時開示する．'}, {'教科名': 'コミュニケーションスキル', '担当者': '和泉\\u3000勇治', '授業目的': '社会における組織について学び，この中で仕事を遂行するためのコミュニケーション能力を身につけることにある。', '教育目標': '(1) 社会における組織内でのコミュニケーションの目的と重要性を理解できる。(2) 相手の意見や主張を把握し他者に説明することができる。(3) 状況に応じた意見の述べ方，表現の方法について理解できる。(4) 意見集約の重要性，合意形成の方法や留意点について理解できる。(5) 意見を他者に適切に伝達するための文章の構成方法について理解できる。(6) 適切なプレゼンテーション資料の作成・構成方法について理解できる。(7) プレゼンテーションの準備，表現方法について理解できる。', '概要': '実社会における組織内でのコミュニケーションは組織の目標を達成するために不可欠なものとなっている。本授業では，コミュニケーションの重要性，方法，留意点について具体的な事例に基づき解説する。第1回から第4回の授業では基本的なコミュニケーションの方法について述べ小テストや課題により理解を深める。第5回，第6回では文書作成の際の準備，自己の意見の整理方法について学び，授業で提示するテーマについての意見整理の実習を行う。第7回から第12回ではプレゼンテーション資料の作成，プレゼンテーション実習，整理文書作成の実習を通し，意見伝達方法の実践的な理解を得る。第13回および第14回ではコミュニケーション事例をビデオにより学習し，様々なコミュニケーション方法について具体的な理解を得る。', '成績評価': '出席および課題提出から総合的に評価する。評価の内訳は，小テスト（60%），プレゼンテーション資料・文書（40%）である。また，評価は絶対評価とする。原則として，授業を4回以上欠席した場合には単位を認定しない。提出物を期限までに提出していない場合は，欠席として取り扱う。なお，提出物を提出していない場合には減点法を取ることにより不合格とする場合がある', '課題': '課題提出後に模範解答等を提示することにより，各自の授業に対する理解度を把握させる。また，提出された課題の講評を授業内で行い，提出内容に対する第三者からの解釈や評価方法について具体的に提示することにより，コミュニケーションの重要性と技術に対する理解を深める。'}, {'教科名': 'Ｗｅｂコンテンツ及び演習', '担当者': '金子 正人、中村 和樹', '授業目的': 'Webページ（ホームページ）の作成・変更を、テキストエディタだけで行えることを目的とする。', '教育目標': '（１）HTML＆CSSの基礎を理解し、それを用いてWebページが作成できる。（２）Web設計および公開方法をWebページの作成演習を通して理解し、さらにページの更新が行える。', '概要': 'Web作成ツールを使ったページ作成では、複数のブラウザに対応したページ作成や細かい変更ができない。そこで、テキストエディタでHTML等を直接変更あるいは一からプログラムすることにより、思い通りのWebページを設計・作成できるように、Webページの仕組みと、HTML＆CSSの基礎を学び、実際のWebページ作成演習を通して身につけていく。画像については利用方法だけでなく、画像ツールの紹介や加工方法についても紹介する。また、作成したWebページについてグループ内外で相互に評価した上で、ページの更新とグループ代表者による発表説明会を行う。', '成績評価': '評価は絶対評価とし、学修進捗＆課題提出状況（30％）および作成したWebページ（70％）により評価し、60点以上を合格とする。 なお、正当な理由無しに4回以上欠席した場合、不合格となる。', '課題': '評価は絶対評価とし、学修進捗＆課題提出状況（30％）および作成したWebページ（70％）により評価し、60点以上を合格とする。 なお、正当な理由無しに4回以上欠席した場合、不合格となる。'}, {'教科名': '数値解析法', '担当者': '宮村\\u3000倫司', '授業目的': '代表的な数値解析手法の理論とアルゴリズムについて理解する。', '教育目標': '(1)浮動小数点，数値誤差について理解する。(2)連立一次方程式の直接解法と反復解法について理解する。(3)最小二乗法，Lagrange補間法等の関数近似法，補間法について理解する。(4)差分と微分方程式の数値解法について理解する。(5)数値積分について理解する。', '概要': '科学技術計算の分野では，コンピュータ（計算機）は計算のための道具として用いられる．そこでは様々な数値解析手法が用いられる。数値計算は「画像処理」，「実験データ処理」，「グラフィックス」といった情報工学関連の科目の基礎となる。教科書を用いた問題演習と代表的な解法を実装するための実習については，別途設置する「数値解析法演習」において行う。', '成績評価': '期末試験 [100%]\\u3000中間試験[下記参照]評価は絶対評価とする。期末試験が60点以上の場合に合格とする。出席回数が少ない場合には，中間試験は採点しない。定期試験が60点未満の場合にのみ，中間試験の成績を考慮する。その場合の得点は最大60点である。', '課題': '中間試験の答案は採点後に返却する。全体の講評，間違いが多かった問題の説明をするので，それをふまえて期末テストに向けて学修する。'}, {'教科名': '数値解析法演習', '担当者': '宮村\\u3000倫司', '授業目的': '代表的な数値解析手法のアルゴリズムを実装し，数値実験ができる。', '教育目標': '(1)代表的な数値解析手法を具体的な問題に適用し，計算ができる。(2)代表的な数値解析手法のアルゴリズムを理解し，プログラムとして実装できる。(3)数値解析のプログラムを用いて数値実験を行える。(4)数値解析の結果を可視化できる。(5)数値解析の結果について考察し，レポートとしてまとめられる。', '概要': '本科目では，別途設置する「数値解析法」に関連した内容について演習を行う。本科目では，様々な数値解析手法をプログラムとして実装するために必要な知識や技術を習得する。授業では，(1)「数値解析法」で学習する各項目に関する問題演習，(2)各自のノートパソコンを用いたプログラム演習を行う。プログラム演習では，C言語により様々な数値解析手法をプログラムとして実装する方法について学ぶ。作成したプログラムを実行して数値実験を行い，計算結果を可視化してレポートとしてまとめる。', '成績評価': '小テスト [60%]\\u3000レポート [30%]\\u3000ノートチェック [10%]評価は絶対評価とする。レポートは授業時間中に作成し，完成しない場合には宿題とする．欠席回数が多い場合やレポートを提出しない場合には不合格となる。', '課題': '小テストの答案は採点後に返却し，次週に解説をする。レポートは採点後返却する。'}, {'教科名': 'アルゴリズム論', '担当者': '若林\\u3000裕之', '授業目的': 'アルゴリズムの概念や記述方法に関する知識を身につけ、アルゴリズムの評価であるオーダ記法等の計算量について理解することを目的とする。', '教育目標': '(1) アルゴリズムの概念 を理解できる(2) アルゴリズムの記述法を理解できる。(3) 計算量評価の概念を理解できる。(4) シンプルなアルゴリズム(素数抽出や再帰処理)について具体的な計算量を評価できる。(5) 探索処理(線形探索 ,２分探索, ハッシュ探索)について計算量を評価できる。(6) 整列処理(バブルソート,最小値選択法, 挿入法, クイックソート, ヒープソート)について計算量を評価できる。(7) 文字列照合処理(単純法, KMP法, BM法)について計算量を評価できる。', '概要': 'プログラムの良否を決定づけるアルゴリズムの概念、アルゴリズムの記述法、および計算量評価手法を学ぶ。さらに、具体的な問題については、各種アルゴリズムをプログラム化したものの計算量評価手法等を学ぶ。具体的な問題として，素数抽出、再帰呼び出し、探索処理，整列処理，文字列処理等をとりあげ，各種問題解決手法について理解を深める。計算量評価手法をより深く理解させるために、実際にプログラムを作成して計算量評価を考察するレポート3回を課す。また，日々の自主学習の目標となるように中間テストを2回実施し，試験終了後に解説を行い理解の向上を図る。', '成績評価': '評価は絶対評価とし、レポートを15点、中間試験を４０点、授業内試験４5点とし、６０点以上を合格とする。原則として４回以上欠席した場合，授業内試験の受験資格を失う。', '課題': '中間試験1および2の解説を行い、各問ごとの得点を開示し、各自の達成度を認識させる。希望する学生には答案および模範回答を開示する。'}, {'教科名': 'オートマトンと言語及び演習', '担当者': '関澤 俊弦', '授業目的': '計算機科学の基礎の一つであり計算機の動作を理解する上で重要となるオートマト，形式文法ンおよび言語を修得し，理論に基づいた演算を行なえるようになることを目的とする。', '教育目標': '(1) 基本的なオートマトンである有限オートマトンとプッシュダウンオートマトンの原理とオートマトンに対する演算アルゴリズムを修得する。(2) 基本的な形式文法である正規文法と文脈自由文法を修得しする。(3) 形式文法と形式言語の関係を修得し，プログラムなど形式言語で記述された文の解析手法を修得する。(4) 各種のオートマトンと形式文法の関係を修得する。', '概要': 'オートマトンと言語を修得し使いこなすためには，動作原理を理解するのみではなく，定義に基づく演算や対象系をモデル化する力が必要となる。そのために，本授業では講義と演習を行なう。講義では，オートマトンと言語の体系を中心として定義や例を解説する。演習では，定義に基づく演算やオートマトンの作成などを行なう。演習の結果はレポートとして提出を求める場合がある。', '成績評価': '評価は絶対評価とする。演習のレポートを20%，中間試験の点数を40%，期末試験の点数を40%として，総合で100点満点として評価を行ない，60点以上を合格とする。', '課題': '演習課題では質問に回答する。ただし，履修人数が多い場合には，個人ではなく全員に対する説明の形で回答することがある。演習課題については，演習時間の解答の進み具合により，一部の問題の解答解説を演習時間内に行なう。中間試験については，授業時間内に解説を行なう。また，採点結果を通知し，達成度を認識させる。'}, {'教科名': 'ソフトウェア設計法及び演習', '担当者': '大山 勝徳', '授業目的': 'ソフトウェア設計の基本概念を修得した上で，各種の図示表現やオブジェクト指向に基づく設計を実現し，設計からテストまでの一連の開発工程を行なえることにある。', '教育目標': '(1) ソフトウェア設計における基本概念である開発プロセス：要件定義や構造化分析などの手法を理解し，ソフトウェアを体系的に開発する手法を理解する。(2) ソフトウェア設計過程で用いるモデルの記法と使い方：データフローダイアグラム(DFD)やUMLなどのソフトウェア設計で用いられる各種モデルの記法と使い方を習得し，ソフトウェア開発プロセスの各フェーズで適切なモデルを用いて設計できるようになる。(3) ソフトウェア設計の体得：開発プロセスおよびモデルを用いたソフトウェア設計の演習を通じて，実際の問題に対してソフトウェア設計手法の適用を行なえるようになる。', '概要': '体系的なソフトウェア開発を行なうためには，設計手法を理解し使いこなせる必要がある。そのために，授業では講義と演習を行なう。授業では，ソフトウェア設計法と関連領域について解説する。演習では，各自のノートパソコンを使用してモデル作成を行なう。設計演習では小規模なシステム開発を具体的な対象として実践的な演習を行ない，レポートを作成する。', '成績評価': '設計演習60%(30%×2回)，および，期末試験(40%)により絶対評価で到達目標が達成されているかを評価し，各クラスの平均点に基づいて成績を決定する。60点以上を合格とする。', '課題': '各回の演習内容について事後に解説を行い，各自の達成度を認識させる。各設計演習の途中成果を用いてレビューを実施し，そのフィードバックに基づいて設計結果を完成させる。'}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "classroom_info_dict = classroom_info.to_dict(orient='record')                                                                   # 読み込んだデータを辞書型に変換\n",
        "print(classroom_info_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "s-0ZiougqEMA"
      },
      "outputs": [],
      "source": [
        "#@title おまじないのセットアップ\n",
        "# 文章を単語毎にスペースで区切ってくれるライブラリ\n",
        "# Mecabのセッティング\n",
        "import MeCab\n",
        "\n",
        "tokenizer = MeCab.Tagger(\"-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd -Owakati\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6d4fE4GrZLg"
      },
      "outputs": [],
      "source": [
        "print(tokenizer.parse(\"学術どうせ参考になるコメント来ないのにめんどくせーなー\")[:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLYE4ly1FoOA"
      },
      "source": [
        "## コンテンツのベクトル化\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ3bmmvSl2o9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ここでは各講義の\n",
        "・授業目的\n",
        "・教育目標\n",
        "・概要\n",
        "の三つの文章を連結し、mecabによって\n",
        "単語の集合に分割してから各単語ベクトルの平均を求めています。\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "class_content = []                                # コンテンツのベクトルを格納するリスト\n",
        "\n",
        "for classroom in classroom_info_dict:             # classroom_info_dictには各授業の概要や教科名などが辞書型になったものがリストとして格納されている。\n",
        "  tmp = \"\"\n",
        "  tmp += classroom[\"授業目的\"]\n",
        "  tmp += classroom[\"教育目標\"]\n",
        "  tmp += classroom[\"概要\"]\n",
        "\n",
        "  sum = np.zeros(300)                             # 授業の文章ベクトルを格納する要素を0とした要素数300ノベクトルを初期化。\n",
        "  words = tokenizer.parse(tmp)[:-1].split(\" \")    # 集約した文章を単語のリストに分割。mecabで分割した際には単語間にスペースが入った文字列として出力。最後の改行は邪魔なので考慮していない。\n",
        "  recg_word_num = 0                               # 文章内で認識できた単語の数を数える\n",
        "  for word in words:\n",
        "    try:\n",
        "      sum += wiki_model[word]\n",
        "      recg_word_num += 1\n",
        "    except KeyError:                              # 学習していない単語の場合は考慮しない\n",
        "      pass\n",
        "  if recg_word_num == 0:                          # もし学習済みの単語がない場合はランダムなベクトルを割り当てる\n",
        "    class_content.append(np.random(300))\n",
        "  else:\n",
        "    class_content.append(sum/recg_word_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tqj2Bm93hsY"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "class_content = np.array(class_content)                                                                   # 保存のためにコンテンツベクトルを集約したものをnumpy配列とする\n",
        "np.save(\"/content/drive/MyDrive/python_ml_intro/content_vec.npy\",class_content)\n",
        "\n",
        "output_content_info = json.dumps(classroom_info_dict,ensure_ascii=False,indent=2)                         # ユーザーに表示するデータとして保存。コンテンツベクトルと添え字を合わせる\n",
        "with open(\"/content/drive/MyDrive/python_ml_intro/content_info_dict.json\",\"w\") as f:\n",
        "  f.write(output_content_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rol11AoUCYH4"
      },
      "source": [
        "## **検索してみよう**\n",
        "せっかくなので検索して今までの成果を確認してみましょう。  \n",
        "文章を入力してそれに近い授業を見つけるのです。\n",
        "\n",
        "### **コンテンツと比較してみよう**\n",
        "\n",
        "いろいろ準備してきましたが、まだ検索はできません。ユーザーの入力はコンテンツのベクトル化と同じやり方で実装できますが、肝心の比較する部分に関して紹介していません。もう少し頑張りましょう。  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMp33mi5ZSsu"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ユーザーの入力をベクトルとして返す関数の定義\n",
        "後でwebアプリ化する際に使用します。\n",
        "\"\"\"\n",
        "\n",
        "def user_input(query: str,m: MeCab.Tagger,wv: KeyedVectors) -> np.ndarray:\n",
        "  sum = np.zeros(300)                               # 授業の文章ベクトルを格納する要素を0とした要素数300ノベクトルを初期化。\n",
        "  words = tokenizer.parse(query)[:-1].split(\" \")    # 集約した文章を単語のリストに分割。mecabで分割した際には単語間にスペースが入った文字列として出力。最後の改行は邪魔なので考慮していない。\n",
        "  recg_word_num = 0                                 # 文章内で認識できた単語の数を数える\n",
        "  for word in words:\n",
        "    try:\n",
        "      sum += wv[word]\n",
        "      recg_word_num += 1\n",
        "    except KeyError:                                # 学習していない単語の場合は考慮しない\n",
        "      pass\n",
        "  if recg_word_num == 0:                            # もし学習済みの単語がない場合はランダムなベクトルを割り当てる\n",
        "    return np.random(300)\n",
        "  else:\n",
        "    return sum / recg_word_num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu1LHuqpb0fa"
      },
      "source": [
        "## コンテンツとの比較\n",
        "\n",
        "コンテンツとの比較とはベクトル同士の比較です。  \n",
        "今回はコサイン尺度を紹介します。その他にもユークリッド距離やピアソン相関などがあります。   \n",
        "コサイン尺度では２つのベクトルΑ,Βがあった時の類似度Tは以下の式で算出されます。  \n",
        "\n",
        "$$Τ = \\frac{Α·Β}{|Α|·|Β|}$$  \n",
        "\n",
        "高校のcosineを座標から求めた時を思い出しましょう。  \n",
        "ベクトルを２次元座標で考えたときに同じであればそれぞれの点と点の角度は0になり(点と点との間に差がない)、まったく違うなら90°,180°になります。全く違うときにそのベクトル同士は直行するといいましたね。その時cosineで0°は１、90°は0になりましたね。0から-1までの数字をとるので、0に近ければ全く違う、1なら同じ、-1なら逆のコンテンツという解釈もできます。これを今回は比較する際の計算式とします。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFaXs3J8kGB8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ユーザーの入力（ベクトル）との比較を行う関数\n",
        "ユーザーの入力と最も類似度が高いコンテンツの添え字を返す\n",
        "\"\"\"\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def culculate_sim(query :np.ndarray ,content_vec :np.ndarray) -> int:\n",
        "  sim_rate = cosine_similarity([query],content_vec)\n",
        "  return np.argmax(sim_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shRLxMjPl6qF"
      },
      "outputs": [],
      "source": [
        "user_query = \"キャリアプラン\"\n",
        "user_vec = user_input(user_query,tokenizer,wiki_model)\n",
        "print(classroom_info_dict[culculate_sim(user_vec,class_content)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mllBtt7sbLd"
      },
      "source": [
        "## 検索結果に満足できたかな？\n",
        "\n",
        "やったね。アプリ化するときの基礎が出来上がったZOY  \n",
        "でも検索結果に満足できたかな？予期しない答えはなかったですか？  \n",
        "\n",
        "### すべてを考慮してはならない\n",
        "\n",
        "何がいけなかったのか。学習データがいけないのでしょうのか（実際辞書であるwikiから学習したモデルに、話し言葉を突っ込むことに違和感はあります）  \n",
        "簡単な解決法としては考慮する単語を減らすことです。文章を読むときに全てにしっかり目を通すでしょうか？  \n",
        "実際は特徴のある単語に目をつけてその単語間のつながりを見ているとも言えます。  \n",
        "例を挙げると「昨日 、 友達 と もつ焼き の 店 に 行 った 。」という文章があった時に「友達」や「行 った」という単語はどの話し言葉にも文章にも表れますが、「もつ焼き」という単語はどの文書にも出てくるとは言えないでしょう。なのでこの文章は「もつ焼き」を中心として成り立っているといえます。  \n",
        "特に今回は文章の特徴を際立たせる必要があるので、文章内で特徴のある単語ベクトルが文章ベクトルに大きく寄与していることが望ましいです。  \n",
        "以下では文章内の単語がどれだけ重要なのか、そしてどれくらい重要なのかを数値で算出するTF-IDFという手法を紹介します。　　\n",
        "\n",
        "### TF-IDF\n",
        "\n",
        "この手法では  \n",
        "- 単語がその文章内でどれだけ出現しているか\n",
        "- 学習するデータ内でどれだけその単語が出現しているか\n",
        "で判断します。　　\n",
        "\n",
        "#### TF(Term Frequency)\n",
        "\n",
        "文章内でどれだけその単語が出現しているかを算出する式です。\n",
        "対象の単語をt、単語が所属する文章をd、学習データ内にある任意の単語をcとすると:\n",
        "$$TF(t,d) = \\frac{num(t)}{\\Sigma  num(c) (c \\in d)}$$\n",
        "となります。文章に含まれる単語のうち、どれだけその単語が占めているかを示しています。  \n",
        "\n",
        "#### IDF(Inverse Document Frequency)\n",
        "\n",
        "学習データ内でどれだけその単語が出現しているかを示します。  \n",
        "TFと違ってこちらは希少であるほうが良いので出現回数が小さいほど数値が大きくなるような式になっています。  \n",
        "対象の単語をt、単語が所属する文章数をdとし、全文章数をnすると:\n",
        "$$IDF(t,d) = \\log \\frac{n}{d(t \\in d)} $$\n",
        "となります。対数をとっているのは文章数が膨大になっても計算可能な範囲に留めておくためです。\n",
        "\n",
        "以上２つの指標を掛けたものが単語がどれだけ重要かを示し指標であるTF-IDFです。  \n",
        "\n",
        "$$TFIDF = TF \\cdot IDF$$\n",
        "\n",
        "これで単語の重要度を数値で表すことができました。  \n",
        "今度はこれを使って文章ベクトルを作る際に各単語ベクトルに重みとしてかけることで接続詞や助詞などのよく出る単語を低くし、固有名詞などの特徴ある単語を際立たせてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTZzV2X1Dx2G"
      },
      "outputs": [],
      "source": [
        "# tf-idfを計算するコードだが、メモリが64G以上ない場合はやめておきましょう\n",
        "from gensim import corpora\n",
        "from gensim.models import TfidfModel\n",
        "\n",
        "dic = corpora.Dictionary(corpus)\n",
        "dic.save_as_text(\"./wiki_dic.dic\",sort_by_word=True)\n",
        "input_corpus = list(map(dic.doc2bow,corpus))                                                                                            # corpusは２次元配列で、各文章を単語のリストとして格納\n",
        "test_model = TfidfModel(input_corpus)\n",
        "test_model.save(\"./wiki_tfidf.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCIUawjdkS6e"
      },
      "outputs": [],
      "source": [
        "from gensim import corpora\n",
        "from gensim.models import TfidfModel\n",
        "\n",
        "dic = corpora.Dictionary.load_from_text(\"https://admiralhonda-share-tech.on.drv.tw/python_ml_intro/data/class_select_app/wiki_dic.dic\")\n",
        "test_model = TfidfModel().load(\"https://admiralhonda-share-tech.on.drv.tw/python_ml_intro/data/class_select_app/wiki_tfidf.model\")\n",
        "\n",
        "\"\"\"\n",
        "ここでは各文章毎に属している単語がどれだけ重要なものであるかを重みづけしていきます。\n",
        "\"\"\"\n",
        "\n",
        "tmp_content_split = [ tokenizer.parse(classroom[\"授業目的\"] + classroom[\"教育目標\"] + classroom[\"概要\"]).replace(\"\\n\",\"\").split(\" \") for classroom in classroom_info_dict]\n",
        "input_corpus = list(map(dic.doc2bow,tmp_content_split))  \n",
        "content_tfidf = test_model[input_corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF7USkSJLP3a"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ここでは各講義の\n",
        "・授業目的\n",
        "・教育目標\n",
        "・概要\n",
        "の三つの文章を連結し、mecabによって\n",
        "単語の集合に分割してから各単語ベクトルにtfidfで得た重みを掛けたベクトルの加重平均を求めています。\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "class_content = []                                # コンテンツのベクトルを格納するリスト\n",
        "\n",
        "for content in content_tfidf:\n",
        "\n",
        "  sum = np.zeros(300)                             # 授業の文章ベクトルを格納する要素を0とした要素数300ノベクトルを初期化。\n",
        "  recg_word_num = 0                               # 文章内で認識できた単語だけtfidfの重みを加算する\n",
        "  for word in content:\n",
        "    try:\n",
        "      sum += wiki_model[dic[word[0]]] * word[1]\n",
        "      recg_word_num += word[1]\n",
        "    except KeyError:                              # 学習していない単語の場合は考慮しない\n",
        "      pass\n",
        "      \n",
        "  if recg_word_num == 0:                          # もし学習済みの単語がない場合はランダムなベクトルを割り当てる\n",
        "    class_content.append(np.random(300))\n",
        "  else:\n",
        "    class_content.append(sum/recg_word_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azO2HS61nAi9"
      },
      "outputs": [],
      "source": [
        "user_query = \"キャリアプラン\"\n",
        "user_vec = user_input(user_query,tokenizer,wiki_model)\n",
        "print(classroom_info_dict[culculate_sim(user_vec,class_content)])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "h1dfw1lJiV8P",
        "-QL5xc0A1pdy",
        "ExF7Mblg4XgJ",
        "QLYE4ly1FoOA",
        "rol11AoUCYH4",
        "Bu1LHuqpb0fa",
        "3mllBtt7sbLd"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "9518b5d8b05613f33dd9892199209c6ea159e58ef30c24ef8a970c59421088c5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
